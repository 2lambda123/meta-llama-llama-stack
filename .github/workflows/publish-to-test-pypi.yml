name: Publish Python üêç distribution üì¶ to TestPyPI

on:
  workflow_dispatch:  # Keep manual trigger
    inputs:
      version:
        description: 'Version number (e.g. 0.0.63.dev20250111)'
        required: true
        type: string
  schedule:
    - cron: "0 0 * * *"  # Run every day at midnight

jobs:
  trigger-client-and-models-build:
    name: Trigger llama-stack-client and llama-models build
    runs-on: ubuntu-latest
    steps:
    - uses: actions/checkout@v4
      with:
        persist-credentials: false
    - name: Get date
      id: date
      run: echo "date=$(date +'%Y%m%d')" >> $GITHUB_OUTPUT
    - name: Compute version based on dispatch event
      id: version
      run: |
        # Read base version from pyproject.toml
        version=$(sed -n 's/.*version="\([^"]*\)".*/\1/p' setup.py)
        if [ "${{ github.event_name }}" = "schedule" ]; then
          echo "version=${version}.dev${{ steps.date.outputs.date }}" >> $GITHUB_OUTPUT
        elif [ "${{ github.event_name }}" = "workflow_dispatch" ]; then
          echo "version=${{ inputs.version }}" >> $GITHUB_OUTPUT
        else
          echo "version=${version}.dev$(shuf -i 10000000-99999999 -n 1)" >> $GITHUB_OUTPUT
        fi
    - name: Trigger llama-stack-client workflow
      run: |
        curl -X POST https://api.github.com/repos/meta-llama/llama-stack-client-python/dispatches \
        -H 'Accept: application/vnd.github.everest-preview+json' \
        -H "authorization: Bearer ${{ secrets.PAT_TOKEN }}" \
        --data "{\"event_type\": \"build-client-package\", \"client_payload\": {\"source\": \"llama-stack-nightly\", \"version\": \"${{ steps.version.outputs.version }}\"}}"
    - name: Trigger llama-models workflow
      run: |
        curl -X POST https://api.github.com/repos/meta-llama/llama-models/dispatches \
        -H 'Accept: application/vnd.github.everest-preview+json' \
        -H "authorization: Bearer ${{ secrets.PAT_TOKEN }}" \
        --data "{\"event_type\": \"build-models-package\", \"client_payload\": {\"source\": \"llama-stack-nightly\", \"version\": \"${{ steps.version.outputs.version }}\"}}"
    outputs:
      version: ${{ steps.version.outputs.version }}

  build:
    name: Build distribution üì¶
    needs: trigger-client-and-models-build  # Wait for client build to complete
    runs-on: ubuntu-latest

    steps:
    - uses: actions/checkout@v4
      with:
        persist-credentials: false
    - name: Get date
      id: date
      run: echo "date=$(date +'%Y%m%d')" >> $GITHUB_OUTPUT
    - name: Update version for nightly
      run: |
        sed -i 's/version="\([^"]*\)"/version="${{ needs.trigger-client-and-models-build.outputs.version }}"/' setup.py
        sed -i 's/llama-stack-client>=\([^"]*\)/llama-stack-client==${{ needs.trigger-client-and-models-build.outputs.version }}/' requirements.txt
        sed -i 's/llama-models>=\([^"]*\)/llama-models==${{ needs.trigger-client-and-models-build.outputs.version }}/' requirements.txt
    - name: Set up Python
      uses: actions/setup-python@v5
      with:
        python-version: "3.11"
    - name: Install pypa/build
      run: >-
        python3 -m
        pip install
        build
        --user
    - name: Build a binary wheel and a source tarball
      run: python3 -m build
    - name: Store the distribution packages
      uses: actions/upload-artifact@v4
      with:
        name: python-package-distributions
        path: dist/

  publish-to-testpypi:
    name: Publish Python üêç distribution üì¶ to TestPyPI
    needs:
    - build
    runs-on: ubuntu-latest

    environment:
      name: testrelease
      url: https://test.pypi.org/p/llama-stack

    permissions:
      id-token: write  # IMPORTANT: mandatory for trusted publishing

    steps:
    - name: Download all the dists
      uses: actions/download-artifact@v4
      with:
        name: python-package-distributions
        path: dist/
    - name: Publish distribution üì¶ to TestPyPI
      uses: pypa/gh-action-pypi-publish@release/v1
      with:
        repository-url: https://test.pypi.org/legacy/
