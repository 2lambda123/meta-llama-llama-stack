name: fireworks
distribution_spec:
  description: Use Fireworks.ai for running LLM inference
  providers:
    inference: remote::fireworks
    memory:
    - meta-reference
    - remote::weaviate
    safety: inline::llama-guard
    agents: meta-reference
    telemetry: meta-reference
